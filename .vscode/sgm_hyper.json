{
    "description": "Settings of Hyper-parameters.",
    "type": "object",
    "required": [
        "data",
        "train"
    ],
    "properties": {
        "data": {
            "description": "Configuration of Data processing",
            "type": "object",
            "properties": {
                "train": {
                    "type": [
                        "string",
                        "array"
                    ],
                    "default": "train"
                },
                "dev": {
                    "type": [
                        "string",
                        "array"
                    ],
                    "default": "dev"
                },
                "test": {
                    "type": [
                        "string",
                        "array"
                    ],
                    "default": "test"
                },
                "filter": {
                    "description": "Range of legal lengths of spectrum frames, split by ':'",
                    "type": "string",
                    "default": ":2000"
                },
                "packing-text-lm": {
                    "type": "object",
                    "properties": {
                        "intext": {
                            "type": "string",
                            "description": "Input text files."
                        },
                        "output": {
                            "type": "string",
                            "description": "Ouput file."
                        },
                        "tokenizer": {
                            "type": "string",
                            "description": "Tokenizer model file. See cat/shared/tokenizer.py for details."
                        },
                        "nj": {
                            "type": "number",
                            "description": "Number of threads. Default: 1",
                            "default": 1
                        },
                        "concat": {
                            "type": "number",
                            "description": "Use concat mode instead valid mode with given length. Default: -1 (disable)",
                            "default": -1
                        },
                        "truncate": {
                            "type": "number",
                            "description": "Truncate the seq longer than trunc and take res of it as new seq. Default: -1 (disable)",
                            "default": -1
                        },
                        "bos_id": {
                            "type": "number",
                            "description": "Begin of sequence index, used when concat > 1. Default: 0",
                            "default": 0
                        },
                        "eos_id": {
                            "type": "number",
                            "description": "End of sequence index, used when concat > 1. Default: -1 (same as --bos_id)",
                            "default": -1
                        },
                        "quiet": {
                            "description": "Supress hint messages",
                            "default": false
                        }
                    },
                    "description": "Convert pure text into pickle data with multi-processing"
                }
            }
        },
        "tokenizer": {
            "type": "object",
            "properties": {
                "type": {
                    "type": "string",
                    "description": "Type of Tokenizer",
                    "examples": [
                        "AbsTokenizer",
                        "JiebaComposeLexiconTokenizer",
                        "JiebaTokenizer",
                        "LexiconTokenizer",
                        "RawTokenizer",
                        "SentencePieceTokenizer",
                        "SimpleTokenizer"
                    ]
                }
            },
            "description": "Configuration of tokenizer",
            "allOf": [
                {
                    "if": {
                        "properties": {
                            "type": {
                                "const": "AbsTokenizer"
                            }
                        }
                    },
                    "then": {
                        "properties": {
                            "option-init": {
                                "type": "object",
                                "properties": {},
                                "description": "options for initializing the tokenizer."
                            },
                            "option-train": {
                                "type": "object",
                                "properties": {},
                                "description": "options for traininig tokenizer."
                            }
                        }
                    }
                },
                {
                    "if": {
                        "properties": {
                            "type": {
                                "const": "JiebaComposeLexiconTokenizer"
                            }
                        }
                    },
                    "then": {
                        "properties": {
                            "option-init": {
                                "type": "object",
                                "properties": {
                                    "lexicon": {
                                        "type": "string"
                                    },
                                    "add_special_token": {
                                        "type": "boolean",
                                        "default": true
                                    },
                                    "bos_interface": {
                                        "type": "string",
                                        "default": "<s>"
                                    },
                                    "unk_interface": {
                                        "type": "string",
                                        "default": "<unk>"
                                    },
                                    "userdict": {}
                                },
                                "description": "options for initializing the tokenizer."
                            },
                            "option-train": {
                                "type": "object",
                                "properties": {},
                                "description": "options for traininig tokenizer."
                            }
                        }
                    }
                },
                {
                    "if": {
                        "properties": {
                            "type": {
                                "const": "JiebaTokenizer"
                            }
                        }
                    },
                    "then": {
                        "properties": {
                            "option-init": {
                                "type": "object",
                                "properties": {
                                    "userdict": {},
                                    "bos_id": {
                                        "type": "number",
                                        "default": 0
                                    }
                                },
                                "description": "options for initializing the tokenizer."
                            },
                            "option-train": {
                                "type": "object",
                                "properties": {},
                                "description": "options for traininig tokenizer."
                            }
                        }
                    }
                },
                {
                    "if": {
                        "properties": {
                            "type": {
                                "const": "LexiconTokenizer"
                            }
                        }
                    },
                    "then": {
                        "properties": {
                            "option-init": {
                                "type": "object",
                                "properties": {
                                    "lexicon": {
                                        "type": "string"
                                    },
                                    "add_special_token": {
                                        "type": "boolean",
                                        "default": true
                                    },
                                    "bos_interface": {
                                        "type": "string",
                                        "default": "<s>"
                                    },
                                    "unk_interface": {
                                        "type": "string",
                                        "default": "<unk>"
                                    }
                                },
                                "description": "options for initializing the tokenizer."
                            },
                            "option-train": {
                                "type": "object",
                                "properties": {},
                                "description": "options for traininig tokenizer."
                            }
                        }
                    }
                },
                {
                    "if": {
                        "properties": {
                            "type": {
                                "const": "RawTokenizer"
                            }
                        }
                    },
                    "then": {
                        "properties": {
                            "option-init": {
                                "type": "object",
                                "properties": {
                                    "num_units": {
                                        "type": "number"
                                    }
                                },
                                "description": "options for initializing the tokenizer."
                            },
                            "option-train": {
                                "type": "object",
                                "properties": {},
                                "description": "options for traininig tokenizer."
                            }
                        }
                    }
                },
                {
                    "if": {
                        "properties": {
                            "type": {
                                "const": "SentencePieceTokenizer"
                            }
                        }
                    },
                    "then": {
                        "properties": {
                            "option-init": {
                                "type": "object",
                                "properties": {
                                    "model_file": {
                                        "type": "string"
                                    }
                                },
                                "description": "options for initializing the tokenizer."
                            },
                            "option-train": {
                                "type": "object",
                                "properties": {
                                    "f_text": {
                                        "type": "string"
                                    },
                                    "model_prefix": {
                                        "type": "string"
                                    },
                                    "vocab_size": {
                                        "type": "number"
                                    },
                                    "add_dummy_prefix": {
                                        "type": "boolean",
                                        "default": true
                                    },
                                    "character_coverage": {
                                        "type": "number",
                                        "default": 0.9995
                                    },
                                    "model_type": {
                                        "default": "unigram"
                                    },
                                    "use_all_vocab": {
                                        "type": "boolean",
                                        "default": false
                                    },
                                    "bos_id": {
                                        "type": "number",
                                        "default": 0
                                    },
                                    "unk_id": {
                                        "type": "number",
                                        "default": 1
                                    },
                                    "eos_id": {
                                        "type": "number",
                                        "default": -1
                                    },
                                    "unk_surface": {
                                        "type": "string",
                                        "default": "<unk>"
                                    },
                                    "minloglevel": {
                                        "type": "number",
                                        "default": 1
                                    },
                                    "user_defined_symbols": {
                                        "type": "string",
                                        "default": ""
                                    },
                                    "train_extremely_large_corpus": {
                                        "type": "boolean",
                                        "default": false
                                    }
                                },
                                "description": "options for traininig tokenizer."
                            }
                        }
                    }
                },
                {
                    "if": {
                        "properties": {
                            "type": {
                                "const": "SimpleTokenizer"
                            }
                        }
                    },
                    "then": {
                        "properties": {
                            "option-init": {
                                "type": "object",
                                "properties": {
                                    "dmap": {},
                                    "read_index_from_file": {
                                        "type": "boolean",
                                        "default": false
                                    }
                                },
                                "description": "options for initializing the tokenizer."
                            },
                            "option-train": {
                                "type": "object",
                                "properties": {},
                                "description": "options for traininig tokenizer."
                            }
                        }
                    }
                }
            ],
            "required": "type"
        },
        "env": {
            "description": "Configure any environment variable if needed.",
            "type": "object",
            "properties": {
                "CUDA_VISIBLE_DEVICES": {
                    "description": "Configure which GPU(s) to be used.",
                    "type": "string",
                    "default": "0,1,2,3"
                },
                "NCCL_SOCKET_IFNAME": {
                    "description": "Configure which network interface to be used.",
                    "type": "string"
                }
            }
        },
        "train": {
            "type": "object",
            "properties": {
                "bin": {
                    "type": "string",
                    "description": "Modules that provides training interface.",
                    "examples": [
                        "cat.rnnt.train_unified",
                        "cat.rnnt.train",
                        "cat.lm.train",
                        "cat.ctc.train"
                    ]
                }
            },
            "description": "Configuration of NN training",
            "required": [
                "bin",
                "option"
            ],
            "allOf": [
                {
                    "if": {
                        "properties": {
                            "bin": {
                                "const": "cat.rnnt.train_unified"
                            }
                        }
                    },
                    "then": {
                        "properties": {
                            "option": {
                                "type": "object",
                                "description": "Unified streaming/offline Transducer training options",
                                "properties": {
                                    "workers": {
                                        "type": "number",
                                        "description": "number of data loading workers (default: 1)",
                                        "default": 1
                                    },
                                    "rank": {
                                        "type": "number",
                                        "description": "node rank for distributed training",
                                        "default": 0
                                    },
                                    "dist_url": {
                                        "type": "string",
                                        "description": "url used to set up distributed training",
                                        "default": "tcp://localhost:13457"
                                    },
                                    "dist_backend": {
                                        "type": "string",
                                        "description": "distributed backend",
                                        "default": "nccl"
                                    },
                                    "world_size": {
                                        "type": "number",
                                        "description": "number of nodes for distributed training",
                                        "default": 1
                                    },
                                    "gpu": {
                                        "type": "number",
                                        "description": "GPU id to use."
                                    },
                                    "print_freq": {
                                        "type": "number",
                                        "description": "print frequency (default: 10)",
                                        "default": 10
                                    },
                                    "batch_size": {
                                        "type": "number",
                                        "description": "mini-batch size (default: 256), this is the total batch size of all GPUs on the current node when using Distributed Data Parallel",
                                        "default": 256
                                    },
                                    "seed": {
                                        "type": "number",
                                        "description": "Manual seed.",
                                        "default": 0
                                    },
                                    "amp": {
                                        "description": "Enable automatic mixed precision training.",
                                        "default": false
                                    },
                                    "grad_accum_fold": {
                                        "type": "number",
                                        "description": "Utilize gradient accumulation for K times. Default: K=1",
                                        "default": 1
                                    },
                                    "grad_norm": {
                                        "type": "number",
                                        "description": "Max norm of the gradients. Default: 0.0 (Disable grad-norm).",
                                        "default": 0.0
                                    },
                                    "debug": {
                                        "description": "Configure to debug settings, would overwrite most of the options.",
                                        "default": false
                                    },
                                    "verbose": {
                                        "description": "Configure to print out more detailed info.",
                                        "default": false
                                    },
                                    "check_freq": {
                                        "type": "number",
                                        "description": "Interval of checkpoints by steps (# of minibatches). Default: -1 (by epoch).",
                                        "default": -1
                                    },
                                    "trset": {
                                        "type": "string",
                                        "description": "Location of training data. Default: <data>/[pickle|hdf5]/tr.[pickle|hdf5]"
                                    },
                                    "devset": {
                                        "type": "string",
                                        "description": "Location of dev data. Default: <data>/[pickle|hdf5]/cv.[pickle|hdf5]"
                                    },
                                    "dir": {
                                        "type": "string",
                                        "description": "Directory to save the log and model files."
                                    },
                                    "dynamic_bucket_size": {
                                        "type": "number",
                                        "description": "The approximate maximum bucket size in dynamic_batch_mode=0.",
                                        "default": -1
                                    },
                                    "dynamic_batch_mode": {
                                        "type": "number",
                                        "description": "Dynamic batching mode. -1: disable; 0: bucket mode; 1: batch mode. default -1.",
                                        "default": -1,
                                        "examples": [
                                            -1,
                                            0,
                                            1
                                        ]
                                    },
                                    "tokenizer": {
                                        "type": "string",
                                        "description": "Specify tokenizer. Currently, only used with --large-dataset."
                                    },
                                    "large_dataset": {
                                        "description": "Use webdataset to load data in POSIX tar format. Be careful with this option, it would change many things than you might think.",
                                        "default": false
                                    },
                                    "config": {
                                        "type": "string",
                                        "description": "Path to configuration file of backbone."
                                    },
                                    "resume": {
                                        "type": "string",
                                        "description": "Path to location of checkpoint."
                                    },
                                    "init_model": {
                                        "type": "string",
                                        "description": "Path to location of checkpoint. This is different from --resume and would only load the parameters of model itself."
                                    }
                                }
                            }
                        }
                    }
                },
                {
                    "if": {
                        "properties": {
                            "bin": {
                                "const": "cat.rnnt.train"
                            }
                        }
                    },
                    "then": {
                        "properties": {
                            "option": {
                                "type": "object",
                                "description": "Transducer training options",
                                "properties": {
                                    "workers": {
                                        "type": "number",
                                        "description": "number of data loading workers (default: 1)",
                                        "default": 1
                                    },
                                    "rank": {
                                        "type": "number",
                                        "description": "node rank for distributed training",
                                        "default": 0
                                    },
                                    "dist_url": {
                                        "type": "string",
                                        "description": "url used to set up distributed training",
                                        "default": "tcp://localhost:13457"
                                    },
                                    "dist_backend": {
                                        "type": "string",
                                        "description": "distributed backend",
                                        "default": "nccl"
                                    },
                                    "world_size": {
                                        "type": "number",
                                        "description": "number of nodes for distributed training",
                                        "default": 1
                                    },
                                    "gpu": {
                                        "type": "number",
                                        "description": "GPU id to use."
                                    },
                                    "print_freq": {
                                        "type": "number",
                                        "description": "print frequency (default: 10)",
                                        "default": 10
                                    },
                                    "batch_size": {
                                        "type": "number",
                                        "description": "mini-batch size (default: 256), this is the total batch size of all GPUs on the current node when using Distributed Data Parallel",
                                        "default": 256
                                    },
                                    "seed": {
                                        "type": "number",
                                        "description": "Manual seed.",
                                        "default": 0
                                    },
                                    "amp": {
                                        "description": "Enable automatic mixed precision training.",
                                        "default": false
                                    },
                                    "grad_accum_fold": {
                                        "type": "number",
                                        "description": "Utilize gradient accumulation for K times. Default: K=1",
                                        "default": 1
                                    },
                                    "grad_norm": {
                                        "type": "number",
                                        "description": "Max norm of the gradients. Default: 0.0 (Disable grad-norm).",
                                        "default": 0.0
                                    },
                                    "debug": {
                                        "description": "Configure to debug settings, would overwrite most of the options.",
                                        "default": false
                                    },
                                    "verbose": {
                                        "description": "Configure to print out more detailed info.",
                                        "default": false
                                    },
                                    "check_freq": {
                                        "type": "number",
                                        "description": "Interval of checkpoints by steps (# of minibatches). Default: -1 (by epoch).",
                                        "default": -1
                                    },
                                    "trset": {
                                        "type": "string",
                                        "description": "Location of training data. Default: <data>/[pickle|hdf5]/tr.[pickle|hdf5]"
                                    },
                                    "devset": {
                                        "type": "string",
                                        "description": "Location of dev data. Default: <data>/[pickle|hdf5]/cv.[pickle|hdf5]"
                                    },
                                    "dir": {
                                        "type": "string",
                                        "description": "Directory to save the log and model files."
                                    },
                                    "dynamic_bucket_size": {
                                        "type": "number",
                                        "description": "The approximate maximum bucket size in dynamic_batch_mode=0.",
                                        "default": -1
                                    },
                                    "dynamic_batch_mode": {
                                        "type": "number",
                                        "description": "Dynamic batching mode. -1: disable; 0: bucket mode; 1: batch mode. default -1.",
                                        "default": -1,
                                        "examples": [
                                            -1,
                                            0,
                                            1
                                        ]
                                    },
                                    "tokenizer": {
                                        "type": "string",
                                        "description": "Specify tokenizer. Currently, only used with --large-dataset."
                                    },
                                    "large_dataset": {
                                        "description": "Use webdataset to load data in POSIX tar format. Be careful with this option, it would change many things than you might think.",
                                        "default": false
                                    },
                                    "config": {
                                        "type": "string",
                                        "description": "Path to configuration file of backbone."
                                    },
                                    "resume": {
                                        "type": "string",
                                        "description": "Path to location of checkpoint."
                                    },
                                    "init_model": {
                                        "type": "string",
                                        "description": "Path to location of checkpoint. This is different from --resume and would only load the parameters of model itself."
                                    }
                                }
                            }
                        }
                    }
                },
                {
                    "if": {
                        "properties": {
                            "bin": {
                                "const": "cat.lm.train"
                            }
                        }
                    },
                    "then": {
                        "properties": {
                            "option": {
                                "type": "object",
                                "description": "Language model trainer. options",
                                "properties": {
                                    "workers": {
                                        "type": "number",
                                        "description": "number of data loading workers (default: 1)",
                                        "default": 1
                                    },
                                    "rank": {
                                        "type": "number",
                                        "description": "node rank for distributed training",
                                        "default": 0
                                    },
                                    "dist_url": {
                                        "type": "string",
                                        "description": "url used to set up distributed training",
                                        "default": "tcp://localhost:13457"
                                    },
                                    "dist_backend": {
                                        "type": "string",
                                        "description": "distributed backend",
                                        "default": "nccl"
                                    },
                                    "world_size": {
                                        "type": "number",
                                        "description": "number of nodes for distributed training",
                                        "default": 1
                                    },
                                    "gpu": {
                                        "type": "number",
                                        "description": "GPU id to use."
                                    },
                                    "print_freq": {
                                        "type": "number",
                                        "description": "print frequency (default: 10)",
                                        "default": 10
                                    },
                                    "batch_size": {
                                        "type": "number",
                                        "description": "mini-batch size (default: 256), this is the total batch size of all GPUs on the current node when using Distributed Data Parallel",
                                        "default": 256
                                    },
                                    "seed": {
                                        "type": "number",
                                        "description": "Manual seed.",
                                        "default": 0
                                    },
                                    "amp": {
                                        "description": "Enable automatic mixed precision training.",
                                        "default": false
                                    },
                                    "grad_accum_fold": {
                                        "type": "number",
                                        "description": "Utilize gradient accumulation for K times. Default: K=1",
                                        "default": 1
                                    },
                                    "grad_norm": {
                                        "type": "number",
                                        "description": "Max norm of the gradients. Default: 0.0 (Disable grad-norm).",
                                        "default": 0.0
                                    },
                                    "debug": {
                                        "description": "Configure to debug settings, would overwrite most of the options.",
                                        "default": false
                                    },
                                    "verbose": {
                                        "description": "Configure to print out more detailed info.",
                                        "default": false
                                    },
                                    "check_freq": {
                                        "type": "number",
                                        "description": "Interval of checkpoints by steps (# of minibatches). Default: -1 (by epoch).",
                                        "default": -1
                                    },
                                    "trset": {
                                        "type": "string",
                                        "description": "Location of training data. Default: <data>/[pickle|hdf5]/tr.[pickle|hdf5]"
                                    },
                                    "devset": {
                                        "type": "string",
                                        "description": "Location of dev data. Default: <data>/[pickle|hdf5]/cv.[pickle|hdf5]"
                                    },
                                    "dir": {
                                        "type": "string",
                                        "description": "Directory to save the log and model files."
                                    },
                                    "dynamic_bucket_size": {
                                        "type": "number",
                                        "description": "The approximate maximum bucket size in dynamic_batch_mode=0.",
                                        "default": -1
                                    },
                                    "dynamic_batch_mode": {
                                        "type": "number",
                                        "description": "Dynamic batching mode. -1: disable; 0: bucket mode; 1: batch mode. default -1.",
                                        "default": -1,
                                        "examples": [
                                            -1,
                                            0,
                                            1
                                        ]
                                    },
                                    "tokenizer": {
                                        "type": "string",
                                        "description": "Specify tokenizer. Currently, only used with --large-dataset."
                                    },
                                    "large_dataset": {
                                        "description": "Use webdataset to load data in POSIX tar format. Be careful with this option, it would change many things than you might think.",
                                        "default": false
                                    },
                                    "config": {
                                        "type": "string",
                                        "description": "Path to configuration file of backbone."
                                    },
                                    "resume": {
                                        "type": "string",
                                        "description": "Path to location of checkpoint."
                                    },
                                    "init_model": {
                                        "type": "string",
                                        "description": "Path to location of checkpoint. This is different from --resume and would only load the parameters of model itself."
                                    }
                                }
                            }
                        }
                    }
                },
                {
                    "if": {
                        "properties": {
                            "bin": {
                                "const": "cat.ctc.train"
                            }
                        }
                    },
                    "then": {
                        "properties": {
                            "option": {
                                "type": "object",
                                "description": "CTC trainer. options",
                                "properties": {
                                    "workers": {
                                        "type": "number",
                                        "description": "number of data loading workers (default: 1)",
                                        "default": 1
                                    },
                                    "rank": {
                                        "type": "number",
                                        "description": "node rank for distributed training",
                                        "default": 0
                                    },
                                    "dist_url": {
                                        "type": "string",
                                        "description": "url used to set up distributed training",
                                        "default": "tcp://localhost:13457"
                                    },
                                    "dist_backend": {
                                        "type": "string",
                                        "description": "distributed backend",
                                        "default": "nccl"
                                    },
                                    "world_size": {
                                        "type": "number",
                                        "description": "number of nodes for distributed training",
                                        "default": 1
                                    },
                                    "gpu": {
                                        "type": "number",
                                        "description": "GPU id to use."
                                    },
                                    "print_freq": {
                                        "type": "number",
                                        "description": "print frequency (default: 10)",
                                        "default": 10
                                    },
                                    "batch_size": {
                                        "type": "number",
                                        "description": "mini-batch size (default: 256), this is the total batch size of all GPUs on the current node when using Distributed Data Parallel",
                                        "default": 256
                                    },
                                    "seed": {
                                        "type": "number",
                                        "description": "Manual seed.",
                                        "default": 0
                                    },
                                    "amp": {
                                        "description": "Enable automatic mixed precision training.",
                                        "default": false
                                    },
                                    "grad_accum_fold": {
                                        "type": "number",
                                        "description": "Utilize gradient accumulation for K times. Default: K=1",
                                        "default": 1
                                    },
                                    "grad_norm": {
                                        "type": "number",
                                        "description": "Max norm of the gradients. Default: 0.0 (Disable grad-norm).",
                                        "default": 0.0
                                    },
                                    "debug": {
                                        "description": "Configure to debug settings, would overwrite most of the options.",
                                        "default": false
                                    },
                                    "verbose": {
                                        "description": "Configure to print out more detailed info.",
                                        "default": false
                                    },
                                    "check_freq": {
                                        "type": "number",
                                        "description": "Interval of checkpoints by steps (# of minibatches). Default: -1 (by epoch).",
                                        "default": -1
                                    },
                                    "trset": {
                                        "type": "string",
                                        "description": "Location of training data. Default: <data>/[pickle|hdf5]/tr.[pickle|hdf5]"
                                    },
                                    "devset": {
                                        "type": "string",
                                        "description": "Location of dev data. Default: <data>/[pickle|hdf5]/cv.[pickle|hdf5]"
                                    },
                                    "dir": {
                                        "type": "string",
                                        "description": "Directory to save the log and model files."
                                    },
                                    "dynamic_bucket_size": {
                                        "type": "number",
                                        "description": "The approximate maximum bucket size in dynamic_batch_mode=0.",
                                        "default": -1
                                    },
                                    "dynamic_batch_mode": {
                                        "type": "number",
                                        "description": "Dynamic batching mode. -1: disable; 0: bucket mode; 1: batch mode. default -1.",
                                        "default": -1,
                                        "examples": [
                                            -1,
                                            0,
                                            1
                                        ]
                                    },
                                    "tokenizer": {
                                        "type": "string",
                                        "description": "Specify tokenizer. Currently, only used with --large-dataset."
                                    },
                                    "large_dataset": {
                                        "description": "Use webdataset to load data in POSIX tar format. Be careful with this option, it would change many things than you might think.",
                                        "default": false
                                    },
                                    "config": {
                                        "type": "string",
                                        "description": "Path to configuration file of backbone."
                                    },
                                    "resume": {
                                        "type": "string",
                                        "description": "Path to location of checkpoint."
                                    },
                                    "init_model": {
                                        "type": "string",
                                        "description": "Path to location of checkpoint. This is different from --resume and would only load the parameters of model itself."
                                    }
                                }
                            }
                        }
                    }
                }
            ]
        },
        "inference": {
            "description": "Basic configuration of NN Training",
            "type": "object",
            "properties": {
                "avgmodel": {
                    "type": "object",
                    "required": [
                        "mode",
                        "num"
                    ],
                    "properties": {
                        "mode": {
                            "type": "string",
                            "examples": [
                                "best",
                                "last"
                            ],
                            "default": "best"
                        },
                        "num": {
                            "type": "number",
                            "default": 10
                        }
                    }
                },
                "er": {
                    "type": "object",
                    "properties": {
                        "gt": {
                            "type": "string",
                            "description": "Ground truth sequences."
                        },
                        "hy": {
                            "type": "string",
                            "description": "Hypothesis of sequences."
                        },
                        "noid": {
                            "description": "Process the text as raw without utterance id. When --oracle, this will be ignored.",
                            "default": false
                        },
                        "cer": {
                            "description": "Compute CER. Default: False",
                            "default": false
                        },
                        "force_cased": {
                            "description": "Force text to be the same cased.",
                            "default": false
                        },
                        "oracle": {
                            "description": "Compute Oracle WER/CER. This requires the `hy` to be N-best list instead of text. Default: False",
                            "default": false
                        }
                    }
                },
                "infer": {
                    "type": "object",
                    "properties": {
                        "bin": {
                            "type": "string",
                            "description": "Modules that provides training interface.",
                            "examples": [
                                "cat.rnnt.decode",
                                "cat.lm.ppl_compute",
                                "cat.lm.rescore",
                                "cat.ctc.cal_logit",
                                "cat.ctc.decode"
                            ]
                        }
                    },
                    "description": "Configuration for inference.",
                    "required": [
                        "bin",
                        "option"
                    ],
                    "allOf": [
                        {
                            "if": {
                                "properties": {
                                    "bin": {
                                        "const": "cat.rnnt.decode"
                                    }
                                }
                            },
                            "then": {
                                "properties": {
                                    "option": {
                                        "type": "object",
                                        "description": "RNN-Transducer decoder. options",
                                        "properties": {
                                            "config": {
                                                "type": "string",
                                                "description": "Path to configuration file of backbone."
                                            },
                                            "resume": {
                                                "type": "string",
                                                "description": "Path to location of checkpoint."
                                            },
                                            "init_model": {
                                                "type": "string",
                                                "description": "Path to location of checkpoint. This is different from --resume and would only load the parameters of model itself."
                                            },
                                            "lm_config": {
                                                "type": "string",
                                                "description": "Config of external LM."
                                            },
                                            "lm_check": {
                                                "type": "string",
                                                "description": "Checkpoint of external LM."
                                            },
                                            "alpha": {
                                                "type": "number",
                                                "description": "Weight of external LM.",
                                                "default": 0.0
                                            },
                                            "beta": {
                                                "type": "number",
                                                "description": "Penalty value of external LM.",
                                                "default": 0.0
                                            },
                                            "ilm_weight": {
                                                "type": "number",
                                                "description": "ILM weight.ilm weight != 0 would enable internal language model estimation. This would slightly slow down the decoding.",
                                                "default": 0.0
                                            },
                                            "input_scp": {
                                                "type": "string"
                                            },
                                            "output_prefix": {
                                                "type": "string",
                                                "default": "./decode"
                                            },
                                            "beam_size": {
                                                "type": "number",
                                                "default": 3
                                            },
                                            "tokenizer": {
                                                "type": "string",
                                                "description": "Tokenizer model file. See cat/shared/tokenizer.py for details."
                                            },
                                            "nj": {
                                                "type": "number",
                                                "default": -1
                                            },
                                            "thread_per_woker": {
                                                "type": "number",
                                                "default": 1
                                            },
                                            "cpu": {
                                                "default": false
                                            },
                                            "silent": {
                                                "default": false
                                            },
                                            "unified": {
                                                "default": false
                                            },
                                            "streaming": {
                                                "default": false
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        {
                            "if": {
                                "properties": {
                                    "bin": {
                                        "const": "cat.lm.ppl_compute"
                                    }
                                }
                            },
                            "then": {
                                "properties": {
                                    "option": {
                                        "type": "object",
                                        "description": "Compute perplexity to evaluate LM. options",
                                        "properties": {
                                            "config": {
                                                "type": "string",
                                                "description": "Path to the configuration file, usually 'path/to/config.json'"
                                            },
                                            "nj": {
                                                "type": "number",
                                                "default": -1
                                            },
                                            "evaluate": {
                                                "type": "string",
                                                "description": "Evaluate test sets. w/o --tokenizer, -e inputs are assumed to be CorpusDataset format binary data."
                                            },
                                            "tokenizer": {
                                                "type": "string",
                                                "description": "Use tokenizer to encode the evaluation sets. If passed, would take -e inputs as text files."
                                            },
                                            "resume": {
                                                "type": "string",
                                                "description": "Path to the checkpoint of NNLM, not required for N-gram LM."
                                            },
                                            "probing_ilm": {
                                                "description": "Probing the LM as ILM, </s> would be excluded due to limitation of E2E model.",
                                                "default": false
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        {
                            "if": {
                                "properties": {
                                    "bin": {
                                        "const": "cat.lm.rescore"
                                    }
                                }
                            },
                            "then": {
                                "properties": {
                                    "option": {
                                        "type": "object",
                                        "description": "Rescore with give n-best list and LM options",
                                        "properties": {
                                            "config": {
                                                "type": "string",
                                                "description": "Path to configuration file of backbone."
                                            },
                                            "resume": {
                                                "type": "string",
                                                "description": "Path to location of checkpoint."
                                            },
                                            "init_model": {
                                                "type": "string",
                                                "description": "Path to location of checkpoint. This is different from --resume and would only load the parameters of model itself."
                                            },
                                            "nbestlist": {
                                                "type": "string",
                                                "description": "Path to N-best list files."
                                            },
                                            "output": {
                                                "type": "string",
                                                "description": "The output text file. "
                                            },
                                            "alpha": {
                                                "type": "number",
                                                "description": "The 'alpha' value for LM integration, a.k.a. the LM weight",
                                                "default": 0.0
                                            },
                                            "beta": {
                                                "type": "number",
                                                "description": "The 'beta' value for LM integration, a.k.a. the penalty of tokens.",
                                                "default": 0.0
                                            },
                                            "tokenizer": {
                                                "type": "string",
                                                "description": "Tokenizer model file. See cat/shared/tokenizer.py for details."
                                            },
                                            "save_lm_nbest": {
                                                "type": "string",
                                                "description": "Path to save the LM N-best scores."
                                            },
                                            "nj": {
                                                "type": "number",
                                                "default": -1
                                            },
                                            "cpu": {
                                                "default": false
                                            },
                                            "verbose": {
                                                "default": false
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        {
                            "if": {
                                "properties": {
                                    "bin": {
                                        "const": "cat.ctc.cal_logit"
                                    }
                                }
                            },
                            "then": {
                                "properties": {
                                    "option": {
                                        "type": "object",
                                        "description": "CTC logit generator. options",
                                        "properties": {
                                            "config": {
                                                "type": "string",
                                                "description": "Path to configuration file of backbone."
                                            },
                                            "resume": {
                                                "type": "string",
                                                "description": "Path to location of checkpoint."
                                            },
                                            "init_model": {
                                                "type": "string",
                                                "description": "Path to location of checkpoint. This is different from --resume and would only load the parameters of model itself."
                                            },
                                            "input_scp": {
                                                "type": "string"
                                            },
                                            "output_dir": {
                                                "type": "string",
                                                "description": "Ouput directory."
                                            },
                                            "nj": {
                                                "type": "number",
                                                "default": -1
                                            },
                                            "built_model_by": {
                                                "type": "string",
                                                "description": "Tell where to import build_model() function. defautl: cat.ctc.train",
                                                "default": "cat.ctc.train"
                                            },
                                            "streaming": {
                                                "default": false
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        {
                            "if": {
                                "properties": {
                                    "bin": {
                                        "const": "cat.ctc.decode"
                                    }
                                }
                            },
                            "then": {
                                "properties": {
                                    "option": {
                                        "type": "object",
                                        "description": "CTC decoder. options",
                                        "properties": {
                                            "config": {
                                                "type": "string",
                                                "description": "Path to configuration file of backbone."
                                            },
                                            "resume": {
                                                "type": "string",
                                                "description": "Path to location of checkpoint."
                                            },
                                            "init_model": {
                                                "type": "string",
                                                "description": "Path to location of checkpoint. This is different from --resume and would only load the parameters of model itself."
                                            },
                                            "input_scp": {
                                                "type": "string"
                                            },
                                            "output_prefix": {
                                                "type": "string",
                                                "default": "./decode"
                                            },
                                            "lm_path": {
                                                "type": "string",
                                                "description": "Path to KenLM model."
                                            },
                                            "alpha": {
                                                "type": "number",
                                                "description": "The 'alpha' value for LM integration, a.k.a. the LM weight",
                                                "default": 0.0
                                            },
                                            "beta": {
                                                "type": "number",
                                                "description": "The 'beta' value for LM integration, a.k.a. the penalty of tokens.",
                                                "default": 0.0
                                            },
                                            "beam_size": {
                                                "type": "number",
                                                "default": 3
                                            },
                                            "do_normalize": {
                                                "description": "Do the log-softmax normalization before beam search.",
                                                "default": false
                                            },
                                            "tokenizer": {
                                                "type": "string",
                                                "description": "Tokenizer model file. See cat/shared/tokenizer.py for details."
                                            },
                                            "gpu": {
                                                "description": "Use GPU to do inference. Default: False.",
                                                "default": false
                                            },
                                            "nj": {
                                                "type": "number",
                                                "default": -1
                                            },
                                            "thread_per_woker": {
                                                "type": "number",
                                                "default": 1
                                            },
                                            "built_model_by": {
                                                "type": "string",
                                                "description": "Tell where to import build_model() function. defautl: cat.ctc.train",
                                                "default": "cat.ctc.train"
                                            },
                                            "streaming": {
                                                "default": false
                                            }
                                        }
                                    }
                                }
                            }
                        }
                    ]
                }
            }
        }
    }
}